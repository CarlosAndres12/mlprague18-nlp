{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on IMDb Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and extract the IMDB sentiment dataset:\n",
    "    \n",
    "    wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "    tar xfz aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 words in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary: All words used, starting by the most frequent\n",
    "with open('aclImdb/imdb.vocab') as f:\n",
    "    vocab = [word.rstrip() for word in f]\n",
    "    # Keep only most frequent 5000 words rather than all 90000\n",
    "    # Just saving memory - the long tail occurs too few times\n",
    "    # for the model to learn anything anyway\n",
    "    vocab = vocab[:5000]\n",
    "    print('%d words in vocabulary' % (len(vocab),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_tokens(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"\\\\s\", \" \", text)\n",
    "    text = re.sub(\"[^a-zA-Z' ]\", \"\", text)\n",
    "    tokens = text.split(' ')\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_dataset(dirname):\n",
    "    X, y = [], []\n",
    "    # Review files: neg/0_3.txt neg/10000_4.txt neg/10001_4.txt ...\n",
    "    for y_val, y_label in enumerate(['neg', 'pos']):\n",
    "        y_dir = os.path.join(dirname, y_label)\n",
    "        for fname in os.listdir(y_dir):\n",
    "            fpath = os.path.join(y_dir, fname)\n",
    "            print('\\r' + fpath + '   ', end='')\n",
    "            with open(fpath) as f:\n",
    "                tokens = text_tokens(f.read())\n",
    "            X.append(tokens)\n",
    "            y.append(y_val)  # 0 for 'neg', 1 for 'pos'\n",
    "    print()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb/train/pos/437_9.txt      \n",
      "aclImdb/test/pos/1917_10.txt    \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_dataset('aclImdb/train/')\n",
    "X_val, y_val = load_dataset('aclImdb/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, Dense, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class BOWSentimentModel(object):\n",
    "    def __init__(self):\n",
    "        bow = Input(shape=(len(vocab),), name='bow_input')\n",
    "        # weights of all inputs\n",
    "        sentiment = Dense(1)(bow)\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        self.model = Model(input=bow, output=sentiment)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * len(vocab)\n",
    "        for t in tokens:\n",
    "            try:\n",
    "                vector[vocab.index(t)] = 1\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X])\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val])\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=25, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X])\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"bo...)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 [==============================] - 5s 183us/step - loss: 0.4518 - acc: 0.8340 - val_loss: 0.3623 - val_acc: 0.8706\n",
      "Epoch 2/25\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 0.3133 - acc: 0.8862 - val_loss: 0.3168 - val_acc: 0.8791\n",
      "Epoch 3/25\n",
      "25000/25000 [==============================] - 3s 105us/step - loss: 0.2726 - acc: 0.9002 - val_loss: 0.3014 - val_acc: 0.8802\n",
      "Epoch 4/25\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.2501 - acc: 0.9070 - val_loss: 0.2939 - val_acc: 0.8812\n",
      "Epoch 5/25\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.2348 - acc: 0.9129 - val_loss: 0.2924 - val_acc: 0.8809\n",
      "Epoch 6/25\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 0.2230 - acc: 0.9180 - val_loss: 0.2918 - val_acc: 0.8813\n",
      "Epoch 7/25\n",
      "25000/25000 [==============================] - 5s 217us/step - loss: 0.2142 - acc: 0.9204 - val_loss: 0.2926 - val_acc: 0.8810\n",
      "Epoch 8/25\n",
      "25000/25000 [==============================] - 5s 182us/step - loss: 0.2068 - acc: 0.9236 - val_loss: 0.2953 - val_acc: 0.8797\n",
      "Epoch 9/25\n",
      "25000/25000 [==============================] - 3s 130us/step - loss: 0.2004 - acc: 0.9267 - val_loss: 0.2997 - val_acc: 0.8764\n",
      "Epoch 10/25\n",
      "25000/25000 [==============================] - 3s 123us/step - loss: 0.1952 - acc: 0.9288 - val_loss: 0.3007 - val_acc: 0.8779\n",
      "Epoch 11/25\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.1907 - acc: 0.9306 - val_loss: 0.3045 - val_acc: 0.8763\n",
      "Epoch 12/25\n",
      "25000/25000 [==============================] - 3s 114us/step - loss: 0.1865 - acc: 0.9328 - val_loss: 0.3093 - val_acc: 0.8735\n",
      "Epoch 13/25\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 0.1830 - acc: 0.9331 - val_loss: 0.3112 - val_acc: 0.8755\n",
      "Epoch 14/25\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 0.1798 - acc: 0.9350 - val_loss: 0.3153 - val_acc: 0.8738\n",
      "Epoch 15/25\n",
      "25000/25000 [==============================] - 3s 130us/step - loss: 0.1770 - acc: 0.9358 - val_loss: 0.3190 - val_acc: 0.8730\n",
      "Epoch 16/25\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.1740 - acc: 0.9369 - val_loss: 0.3263 - val_acc: 0.8694\n",
      "Epoch 17/25\n",
      "25000/25000 [==============================] - 3s 113us/step - loss: 0.1714 - acc: 0.9373 - val_loss: 0.3267 - val_acc: 0.8704\n",
      "Epoch 18/25\n",
      "25000/25000 [==============================] - 3s 121us/step - loss: 0.1693 - acc: 0.9378 - val_loss: 0.3301 - val_acc: 0.8694\n",
      "Epoch 19/25\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.1671 - acc: 0.9383 - val_loss: 0.3337 - val_acc: 0.8684\n",
      "Epoch 20/25\n",
      "25000/25000 [==============================] - 2s 96us/step - loss: 0.1650 - acc: 0.9388 - val_loss: 0.3383 - val_acc: 0.8673\n",
      "Epoch 21/25\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.1631 - acc: 0.9406 - val_loss: 0.3422 - val_acc: 0.8658\n",
      "Epoch 22/25\n",
      "25000/25000 [==============================] - 3s 120us/step - loss: 0.1616 - acc: 0.9410 - val_loss: 0.3460 - val_acc: 0.8653\n",
      "Epoch 23/25\n",
      "25000/25000 [==============================] - 3s 110us/step - loss: 0.1600 - acc: 0.9410 - val_loss: 0.3487 - val_acc: 0.8642\n",
      "Epoch 24/25\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.1583 - acc: 0.9421 - val_loss: 0.3534 - val_acc: 0.8638\n",
      "Epoch 25/25\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.1569 - acc: 0.9422 - val_loss: 0.3560 - val_acc: 0.8631\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.86290973]\n"
     ]
    }
   ],
   "source": [
    "sentiment = BOWSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words with Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, Dense, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class BOWHiddenSentimentModel(object):\n",
    "    def __init__(self, N=64):\n",
    "        bow = Input(shape=(len(vocab),), name='bow_input')\n",
    "        # weights of all inputs\n",
    "        hidden = Dense(N, activation='tanh')(bow)\n",
    "        sentiment = Dense(1)(hidden)\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        self.model = Model(input=bow, output=sentiment)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * len(vocab)\n",
    "        for t in tokens:\n",
    "            try:\n",
    "                vector[vocab.index(t)] = 1\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X])\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val])\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=25, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X])\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"bo...)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 [==============================] - 16s 645us/step - loss: 0.3276 - acc: 0.8598 - val_loss: 0.3017 - val_acc: 0.8728\n",
      "Epoch 2/25\n",
      "25000/25000 [==============================] - 13s 502us/step - loss: 0.2335 - acc: 0.9052 - val_loss: 0.3119 - val_acc: 0.8682\n",
      "Epoch 3/25\n",
      "25000/25000 [==============================] - 15s 593us/step - loss: 0.2025 - acc: 0.9163 - val_loss: 0.3262 - val_acc: 0.8680\n",
      "Epoch 4/25\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 0.1772 - acc: 0.9297 - val_loss: 0.3350 - val_acc: 0.8619\n",
      "Epoch 5/25\n",
      "25000/25000 [==============================] - 13s 508us/step - loss: 0.1503 - acc: 0.9397 - val_loss: 0.3674 - val_acc: 0.8601\n",
      "Epoch 6/25\n",
      "25000/25000 [==============================] - 12s 469us/step - loss: 0.1219 - acc: 0.9526 - val_loss: 0.4186 - val_acc: 0.8573\n",
      "Epoch 7/25\n",
      "25000/25000 [==============================] - 14s 564us/step - loss: 0.0914 - acc: 0.9676 - val_loss: 0.4648 - val_acc: 0.8542\n",
      "Epoch 8/25\n",
      "25000/25000 [==============================] - 17s 661us/step - loss: 0.0619 - acc: 0.9814 - val_loss: 0.5176 - val_acc: 0.8524\n",
      "Epoch 9/25\n",
      "25000/25000 [==============================] - 14s 568us/step - loss: 0.0401 - acc: 0.9896 - val_loss: 0.5777 - val_acc: 0.8510\n",
      "Epoch 10/25\n",
      "25000/25000 [==============================] - 15s 591us/step - loss: 0.0229 - acc: 0.9954 - val_loss: 0.6435 - val_acc: 0.8493\n",
      "Epoch 11/25\n",
      "25000/25000 [==============================] - 14s 577us/step - loss: 0.0123 - acc: 0.9982 - val_loss: 0.7014 - val_acc: 0.8502\n",
      "Epoch 12/25\n",
      "25000/25000 [==============================] - 12s 481us/step - loss: 0.0069 - acc: 0.9993 - val_loss: 0.7617 - val_acc: 0.8483\n",
      "Epoch 13/25\n",
      "25000/25000 [==============================] - 12s 465us/step - loss: 0.0036 - acc: 0.9998 - val_loss: 0.8211 - val_acc: 0.8493\n",
      "Epoch 14/25\n",
      "25000/25000 [==============================] - 12s 479us/step - loss: 0.0021 - acc: 0.9999 - val_loss: 0.8636 - val_acc: 0.8491\n",
      "Epoch 15/25\n",
      "25000/25000 [==============================] - 12s 492us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.8946 - val_acc: 0.8481\n",
      "Epoch 16/25\n",
      "25000/25000 [==============================] - 13s 514us/step - loss: 8.4997e-04 - acc: 0.9999 - val_loss: 0.9347 - val_acc: 0.8483\n",
      "Epoch 17/25\n",
      "25000/25000 [==============================] - 12s 473us/step - loss: 5.4185e-04 - acc: 1.0000 - val_loss: 0.9547 - val_acc: 0.8488\n",
      "Epoch 18/25\n",
      "25000/25000 [==============================] - 16s 626us/step - loss: 3.6357e-04 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.8489\n",
      "Epoch 19/25\n",
      "25000/25000 [==============================] - 12s 478us/step - loss: 2.4496e-04 - acc: 1.0000 - val_loss: 1.0220 - val_acc: 0.8478\n",
      "Epoch 20/25\n",
      "25000/25000 [==============================] - 11s 450us/step - loss: 1.7269e-04 - acc: 1.0000 - val_loss: 1.0489 - val_acc: 0.8490\n",
      "Epoch 21/25\n",
      "25000/25000 [==============================] - 11s 453us/step - loss: 1.2359e-04 - acc: 1.0000 - val_loss: 1.0716 - val_acc: 0.8488\n",
      "Epoch 22/25\n",
      "25000/25000 [==============================] - 12s 462us/step - loss: 8.8478e-05 - acc: 1.0000 - val_loss: 1.0907 - val_acc: 0.8488\n",
      "Epoch 23/25\n",
      "25000/25000 [==============================] - 12s 463us/step - loss: 5.7527e-05 - acc: 1.0000 - val_loss: 1.1171 - val_acc: 0.8501\n",
      "Epoch 24/25\n",
      "25000/25000 [==============================] - 13s 506us/step - loss: 4.2332e-05 - acc: 1.0000 - val_loss: 1.1377 - val_acc: 0.8482\n",
      "Epoch 25/25\n",
      "25000/25000 [==============================] - 13s 515us/step - loss: 3.0768e-05 - acc: 1.0000 - val_loss: 1.1518 - val_acc: 0.8490\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 1.]\n"
     ]
    }
   ],
   "source": [
    "sentiment = BOWHiddenSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe-based Model (let's start with averaging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading GloVe vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# let's create a dictionary of each word in the pre-trained GloVe embeddings, saving its location indexes \n",
    "import os\n",
    "GLOVE_DIR = \".\" # ./glove.6B/\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.%dd.txt' % EMBEDDING_DIM))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "for i, word in enumerate(vocab):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        # also, [0] is reserved for padding\n",
    "        embedding_matrix[i + 1] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking how many words have no pre-trained GloVe word embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0076"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. * np.count_nonzero(np.all(embedding_matrix == 0, axis=1)) / len(vocab)  # OOV portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing reviews as sequences: What's a good compromise for sequence length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 233.778560, Median: 174, 66% percentile: 232 tokens\n"
     ]
    }
   ],
   "source": [
    "lengths = sorted([len(X) for X in X_train])\n",
    "percentile = 0.66\n",
    "seq_cutoff = lengths[int(len(lengths)*percentile)]\n",
    "print('Average: %f, Median: %d, %d%% percentile: %d tokens' % (np.mean(lengths), lengths[int(len(lengths)*0.5)], percentile*100, seq_cutoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe averaging model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "  * Predict sentiment from mean embedding, or mean sentiment from each embedding?\n",
    "  * `trainable=True`?\n",
    "  * Projection to a \"sentiment predictive\" space first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, GlobalAveragePooling1D, Dense, Embedding, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveAvgSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        avg_embedded = GlobalAveragePooling1D()(seq_embedded)\n",
    "        sentiment = Dense(1)(avg_embedded)\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=25, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 0.6759 - acc: 0.6161 - val_loss: 0.6648 - val_acc: 0.6427\n",
      "Epoch 2/25\n",
      "25000/25000 [==============================] - 2s 93us/step - loss: 0.6538 - acc: 0.6610 - val_loss: 0.6478 - val_acc: 0.6616\n",
      "Epoch 3/25\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 0.6387 - acc: 0.6716 - val_loss: 0.6361 - val_acc: 0.6678\n",
      "Epoch 4/25\n",
      "25000/25000 [==============================] - 2s 95us/step - loss: 0.6275 - acc: 0.6806 - val_loss: 0.6263 - val_acc: 0.6758\n",
      "Epoch 5/25\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 0.6183 - acc: 0.6862 - val_loss: 0.6183 - val_acc: 0.6820\n",
      "Epoch 6/25\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.6106 - acc: 0.6921 - val_loss: 0.6113 - val_acc: 0.6887\n",
      "Epoch 7/25\n",
      "25000/25000 [==============================] - 2s 96us/step - loss: 0.6040 - acc: 0.6973 - val_loss: 0.6055 - val_acc: 0.6921\n",
      "Epoch 8/25\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.5982 - acc: 0.7026 - val_loss: 0.5999 - val_acc: 0.6982\n",
      "Epoch 9/25\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.5929 - acc: 0.7088 - val_loss: 0.5950 - val_acc: 0.7023\n",
      "Epoch 10/25\n",
      "25000/25000 [==============================] - 2s 96us/step - loss: 0.5880 - acc: 0.7136 - val_loss: 0.5909 - val_acc: 0.7048\n",
      "Epoch 11/25\n",
      "25000/25000 [==============================] - 2s 94us/step - loss: 0.5837 - acc: 0.7157 - val_loss: 0.5866 - val_acc: 0.7091\n",
      "Epoch 12/25\n",
      "25000/25000 [==============================] - 3s 122us/step - loss: 0.5800 - acc: 0.7184 - val_loss: 0.5829 - val_acc: 0.7107\n",
      "Epoch 13/25\n",
      "25000/25000 [==============================] - 3s 119us/step - loss: 0.5765 - acc: 0.7198 - val_loss: 0.5801 - val_acc: 0.7122\n",
      "Epoch 14/25\n",
      "25000/25000 [==============================] - 3s 112us/step - loss: 0.5732 - acc: 0.7223 - val_loss: 0.5771 - val_acc: 0.7144\n",
      "Epoch 15/25\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.5703 - acc: 0.7252 - val_loss: 0.5738 - val_acc: 0.7175\n",
      "Epoch 16/25\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.5675 - acc: 0.7267 - val_loss: 0.5717 - val_acc: 0.7189\n",
      "Epoch 17/25\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 0.5652 - acc: 0.7284 - val_loss: 0.5689 - val_acc: 0.7213\n",
      "Epoch 18/25\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 0.5629 - acc: 0.7301 - val_loss: 0.5666 - val_acc: 0.7221\n",
      "Epoch 19/25\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.5607 - acc: 0.7308 - val_loss: 0.5646 - val_acc: 0.7242\n",
      "Epoch 20/25\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.5588 - acc: 0.7326 - val_loss: 0.5628 - val_acc: 0.7243\n",
      "Epoch 21/25\n",
      "25000/25000 [==============================] - 3s 110us/step - loss: 0.5569 - acc: 0.7338 - val_loss: 0.5614 - val_acc: 0.7240\n",
      "Epoch 22/25\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.5552 - acc: 0.7344 - val_loss: 0.5597 - val_acc: 0.7253\n",
      "Epoch 23/25\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.5535 - acc: 0.7352 - val_loss: 0.5579 - val_acc: 0.7272\n",
      "Epoch 24/25\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 0.5521 - acc: 0.7361 - val_loss: 0.5565 - val_acc: 0.7282\n",
      "Epoch 25/25\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.5507 - acc: 0.7366 - val_loss: 0.5557 - val_acc: 0.7269\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.66820341]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveAvgSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, GlobalAveragePooling1D, Dense, Embedding, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveSentimentAvgModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_sentiment = Dense(1)(seq_embedded)\n",
    "        # normalize to [0, 1] range\n",
    "        seq_sentiment = Activation('sigmoid')(seq_sentiment)\n",
    "        sentiment = GlobalAveragePooling1D()(seq_sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=25, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"gl..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 [==============================] - 4s 141us/step - loss: 0.6811 - acc: 0.6116 - val_loss: 0.6736 - val_acc: 0.6403\n",
      "Epoch 2/25\n",
      "25000/25000 [==============================] - 3s 135us/step - loss: 0.6686 - acc: 0.6583 - val_loss: 0.6673 - val_acc: 0.6573\n",
      "Epoch 3/25\n",
      "25000/25000 [==============================] - 3s 129us/step - loss: 0.6641 - acc: 0.6653 - val_loss: 0.6643 - val_acc: 0.6594\n",
      "Epoch 4/25\n",
      "25000/25000 [==============================] - 3s 138us/step - loss: 0.6616 - acc: 0.6654 - val_loss: 0.6626 - val_acc: 0.6616\n",
      "Epoch 5/25\n",
      "25000/25000 [==============================] - 3s 129us/step - loss: 0.6600 - acc: 0.6693 - val_loss: 0.6620 - val_acc: 0.6580\n",
      "Epoch 6/25\n",
      "25000/25000 [==============================] - 4s 141us/step - loss: 0.6591 - acc: 0.6726 - val_loss: 0.6605 - val_acc: 0.6642\n",
      "Epoch 7/25\n",
      "25000/25000 [==============================] - 3s 124us/step - loss: 0.6582 - acc: 0.6710 - val_loss: 0.6598 - val_acc: 0.6641\n",
      "Epoch 8/25\n",
      "25000/25000 [==============================] - 3s 126us/step - loss: 0.6575 - acc: 0.6728 - val_loss: 0.6594 - val_acc: 0.6646\n",
      "Epoch 9/25\n",
      "25000/25000 [==============================] - 3s 137us/step - loss: 0.6570 - acc: 0.6748 - val_loss: 0.6588 - val_acc: 0.6653\n",
      "Epoch 10/25\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.6565 - acc: 0.6726 - val_loss: 0.6584 - val_acc: 0.6639\n",
      "Epoch 11/25\n",
      "25000/25000 [==============================] - 3s 131us/step - loss: 0.6562 - acc: 0.6727 - val_loss: 0.6580 - val_acc: 0.6664\n",
      "Epoch 12/25\n",
      "25000/25000 [==============================] - 3s 137us/step - loss: 0.6559 - acc: 0.6748 - val_loss: 0.6578 - val_acc: 0.6664\n",
      "Epoch 13/25\n",
      "25000/25000 [==============================] - 4s 141us/step - loss: 0.6556 - acc: 0.6755 - val_loss: 0.6575 - val_acc: 0.6665\n",
      "Epoch 14/25\n",
      "25000/25000 [==============================] - 3s 128us/step - loss: 0.6553 - acc: 0.6737 - val_loss: 0.6574 - val_acc: 0.6629\n",
      "Epoch 15/25\n",
      "25000/25000 [==============================] - 4s 145us/step - loss: 0.6551 - acc: 0.6727 - val_loss: 0.6571 - val_acc: 0.6670\n",
      "Epoch 16/25\n",
      "25000/25000 [==============================] - 4s 171us/step - loss: 0.6548 - acc: 0.6737 - val_loss: 0.6570 - val_acc: 0.6651\n",
      "Epoch 17/25\n",
      "25000/25000 [==============================] - 3s 135us/step - loss: 0.6546 - acc: 0.6728 - val_loss: 0.6568 - val_acc: 0.6647\n",
      "Epoch 18/25\n",
      "25000/25000 [==============================] - 3s 130us/step - loss: 0.6545 - acc: 0.6751 - val_loss: 0.6566 - val_acc: 0.6680\n",
      "Epoch 19/25\n",
      "25000/25000 [==============================] - 3s 134us/step - loss: 0.6543 - acc: 0.6729 - val_loss: 0.6565 - val_acc: 0.6669\n",
      "Epoch 20/25\n",
      "25000/25000 [==============================] - 3s 127us/step - loss: 0.6542 - acc: 0.6753 - val_loss: 0.6563 - val_acc: 0.6674\n",
      "Epoch 21/25\n",
      "25000/25000 [==============================] - 3s 136us/step - loss: 0.6540 - acc: 0.6746 - val_loss: 0.6562 - val_acc: 0.6674\n",
      "Epoch 22/25\n",
      "25000/25000 [==============================] - 3s 129us/step - loss: 0.6539 - acc: 0.6759 - val_loss: 0.6561 - val_acc: 0.6659\n",
      "Epoch 23/25\n",
      "25000/25000 [==============================] - 3s 128us/step - loss: 0.6538 - acc: 0.6768 - val_loss: 0.6560 - val_acc: 0.6657\n",
      "Epoch 24/25\n",
      "25000/25000 [==============================] - 3s 126us/step - loss: 0.6537 - acc: 0.6764 - val_loss: 0.6560 - val_acc: 0.6639\n",
      "Epoch 25/25\n",
      "25000/25000 [==============================] - 3s 127us/step - loss: 0.6535 - acc: 0.6747 - val_loss: 0.6558 - val_acc: 0.6683\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.57322681]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveSentimentAvgModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, GlobalMaxPooling1D, Dense, Embedding, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveHiddenMaxSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(seq_embedded)\n",
    "        max_hidden = GlobalMaxPooling1D()(seq_hidden)\n",
    "        sentiment = Dense(1)(max_hidden)\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=25, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 [==============================] - 32s 1ms/step - loss: 0.5609 - acc: 0.7220 - val_loss: 0.4680 - val_acc: 0.7864\n",
      "Epoch 2/25\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.4403 - acc: 0.8014 - val_loss: 0.4283 - val_acc: 0.8055\n",
      "Epoch 3/25\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.4051 - acc: 0.8201 - val_loss: 0.4094 - val_acc: 0.8149\n",
      "Epoch 4/25\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.3860 - acc: 0.8296 - val_loss: 0.4032 - val_acc: 0.8171\n",
      "Epoch 5/25\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.3715 - acc: 0.8369 - val_loss: 0.3951 - val_acc: 0.8224\n",
      "Epoch 6/25\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3588 - acc: 0.8412 - val_loss: 0.3899 - val_acc: 0.8248\n",
      "Epoch 7/25\n",
      "25000/25000 [==============================] - 31s 1ms/step - loss: 0.3507 - acc: 0.8458 - val_loss: 0.4016 - val_acc: 0.8168\n",
      "Epoch 8/25\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.3430 - acc: 0.8496 - val_loss: 0.3894 - val_acc: 0.8246\n",
      "Epoch 9/25\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.3358 - acc: 0.8544 - val_loss: 0.3927 - val_acc: 0.8230\n",
      "Epoch 10/25\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.3297 - acc: 0.8572 - val_loss: 0.3877 - val_acc: 0.8266\n",
      "Epoch 11/25\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.3252 - acc: 0.8612"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-37950d284e17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGloveHiddenMaxSentimentModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-460687874a73>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1247\u001b[0m                             val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1248\u001b[0m                                                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                                                        verbose=0)\n\u001b[0m\u001b[1;32m   1250\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                                 \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentiment = GloveHiddenMaxSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, Embedding, GRU, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveHiddenGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(seq_embedded)\n",
    "        recursive_repr = GRU(N)(seq_hidden)\n",
    "        sentiment = Dense(1)(recursive_repr)\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=5, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 185s 7ms/step - loss: 0.6545 - acc: 0.5852 - val_loss: 0.6469 - val_acc: 0.5911\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 164s 7ms/step - loss: 0.4373 - acc: 0.7940 - val_loss: 0.4233 - val_acc: 0.8076\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 186s 7ms/step - loss: 0.3748 - acc: 0.8348 - val_loss: 0.3654 - val_acc: 0.8360\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.3534 - acc: 0.8432 - val_loss: 0.3453 - val_acc: 0.8469\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 171s 7ms/step - loss: 0.3302 - acc: 0.8550 - val_loss: 0.3289 - val_acc: 0.8518\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.94238299]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveHiddenGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Embedding, GlobalMaxPooling1D, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveHiddenCNNSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(seq_embedded)\n",
    "        seq_conv = Conv1D(N, size)(seq_hidden)\n",
    "        max_conv = GlobalMaxPooling1D()(seq_conv)\n",
    "        sentiment = Dense(1)(max_conv)\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=10, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 63s 3ms/step - loss: 0.5234 - acc: 0.7374 - val_loss: 0.4291 - val_acc: 0.8026\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.4384 - acc: 0.7962 - val_loss: 0.4023 - val_acc: 0.8175\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.4104 - acc: 0.8142 - val_loss: 0.3827 - val_acc: 0.8284\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.3956 - acc: 0.8207 - val_loss: 0.3894 - val_acc: 0.8242\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.3791 - acc: 0.8314 - val_loss: 0.3641 - val_acc: 0.8367\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.3709 - acc: 0.8348 - val_loss: 0.3510 - val_acc: 0.8427\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.3615 - acc: 0.8404 - val_loss: 0.3570 - val_acc: 0.8399\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 62s 2ms/step - loss: 0.3517 - acc: 0.8426 - val_loss: 0.3659 - val_acc: 0.8380\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.3489 - acc: 0.8464 - val_loss: 0.3394 - val_acc: 0.8520\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.3417 - acc: 0.8518 - val_loss: 0.3370 - val_acc: 0.8514\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.98872828]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveHiddenCNNSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Embedding, GRU, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = seq_embedded  # Dense(N, activation='tanh')(seq_embedded)\n",
    "        seq_conv = Conv1D(N, size, activation='tanh')(seq_hidden)\n",
    "        recursive_repr = GRU(N)(seq_conv)\n",
    "        sentiment = Dense(1)(recursive_repr)\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=10, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, GRU, Input, concatenate, add\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh', padding='same')(Dropout(0.2)(seq_hidden))\n",
    "        seq_hidden = add([seq_hidden, seq_conv])\n",
    "        recursive_repr = GRU(N)(Dropout(0.2)(seq_hidden))\n",
    "        sentiment = Dense(1)(Dropout(0.2)(recursive_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.6920 - acc: 0.5236 - val_loss: 0.6781 - val_acc: 0.5440\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 228s 9ms/step - loss: 0.5711 - acc: 0.6836 - val_loss: 0.4038 - val_acc: 0.8200\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 198s 8ms/step - loss: 0.4324 - acc: 0.7999 - val_loss: 0.3726 - val_acc: 0.8324\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 197s 8ms/step - loss: 0.4073 - acc: 0.8129 - val_loss: 0.3636 - val_acc: 0.8359\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 198s 8ms/step - loss: 0.3950 - acc: 0.8211 - val_loss: 0.3529 - val_acc: 0.8409\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 190s 8ms/step - loss: 0.3844 - acc: 0.8274 - val_loss: 0.3483 - val_acc: 0.8474\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 201s 8ms/step - loss: 0.3754 - acc: 0.8323 - val_loss: 0.3946 - val_acc: 0.8154\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.3645 - acc: 0.8376 - val_loss: 0.3286 - val_acc: 0.8560\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 189s 8ms/step - loss: 0.3599 - acc: 0.8396 - val_loss: 0.3480 - val_acc: 0.8441\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 182s 7ms/step - loss: 0.3551 - acc: 0.8428 - val_loss: 0.3188 - val_acc: 0.8588\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 193s 8ms/step - loss: 0.3456 - acc: 0.8485 - val_loss: 0.3175 - val_acc: 0.8615\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 204s 8ms/step - loss: 0.3442 - acc: 0.8481 - val_loss: 0.3135 - val_acc: 0.8648\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 189s 8ms/step - loss: 0.3380 - acc: 0.8507 - val_loss: 0.3111 - val_acc: 0.8654\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 190s 8ms/step - loss: 0.3358 - acc: 0.8503 - val_loss: 0.3161 - val_acc: 0.8644\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 197s 8ms/step - loss: 0.3309 - acc: 0.8530 - val_loss: 0.3112 - val_acc: 0.8648\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.96565175]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, GRU, Input, concatenate, add\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=96, size=5):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh', padding='same')(Dropout(0.2)(seq_hidden))\n",
    "        seq_hidden = add([seq_hidden, seq_conv])\n",
    "        recursive_repr = GRU(N)(Dropout(0.2)(seq_hidden))\n",
    "        sentiment = Dense(1)(Dropout(0.2)(recursive_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 358s 14ms/step - loss: 0.6742 - acc: 0.5536 - val_loss: 0.5806 - val_acc: 0.7067\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 339s 14ms/step - loss: 0.4957 - acc: 0.7601 - val_loss: 0.4023 - val_acc: 0.8146\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 300s 12ms/step - loss: 0.4336 - acc: 0.8006 - val_loss: 0.3885 - val_acc: 0.8228\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 325s 13ms/step - loss: 0.4143 - acc: 0.8102 - val_loss: 0.3790 - val_acc: 0.8273\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 343s 14ms/step - loss: 0.3990 - acc: 0.8172 - val_loss: 0.3682 - val_acc: 0.8340\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 346s 14ms/step - loss: 0.3876 - acc: 0.8240 - val_loss: 0.3455 - val_acc: 0.8453\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 336s 13ms/step - loss: 0.3764 - acc: 0.8319 - val_loss: 0.3472 - val_acc: 0.8444\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 367s 15ms/step - loss: 0.3669 - acc: 0.8375 - val_loss: 0.3646 - val_acc: 0.8396\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 399s 16ms/step - loss: 0.3585 - acc: 0.8408 - val_loss: 0.3351 - val_acc: 0.8506\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 334s 13ms/step - loss: 0.3550 - acc: 0.8431 - val_loss: 0.3313 - val_acc: 0.8548\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 351s 14ms/step - loss: 0.3417 - acc: 0.8492 - val_loss: 0.3487 - val_acc: 0.8500\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 13448s 538ms/step - loss: 0.3340 - acc: 0.8546 - val_loss: 0.3210 - val_acc: 0.8576\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 311s 12ms/step - loss: 0.3290 - acc: 0.8550 - val_loss: 0.3187 - val_acc: 0.8619\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 326s 13ms/step - loss: 0.3237 - acc: 0.8588 - val_loss: 0.3194 - val_acc: 0.8615\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 322s 13ms/step - loss: 0.3211 - acc: 0.8595 - val_loss: 0.3154 - val_acc: 0.8606\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.96519709]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# let's create a dictionary of each word in the pre-trained GloVe embeddings, saving its location indexes \n",
    "import os\n",
    "GLOVE_DIR = \".\" # ./glove.6B/\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.%dd.txt' % EMBEDDING_DIM))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "for i, word in enumerate(vocab):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        # also, [0] is reserved for padding\n",
    "        embedding_matrix[i + 1] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Embedding, GRU, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = seq_embedded  # Dense(N, activation='tanh')(seq_embedded)\n",
    "        seq_conv = Conv1D(N, size, activation='tanh')(seq_hidden)\n",
    "        recursive_repr = GRU(N)(seq_conv)\n",
    "        sentiment = Dense(1)(recursive_repr)\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=10, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 267s 11ms/step - loss: 0.5957 - acc: 0.6341 - val_loss: 0.4103 - val_acc: 0.8148\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 258s 10ms/step - loss: 0.3466 - acc: 0.8490 - val_loss: 0.3117 - val_acc: 0.8654\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.2985 - acc: 0.8742 - val_loss: 0.2999 - val_acc: 0.8692\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 261s 10ms/step - loss: 0.2601 - acc: 0.8944 - val_loss: 0.2963 - val_acc: 0.8718\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 249s 10ms/step - loss: 0.2280 - acc: 0.9089 - val_loss: 0.3158 - val_acc: 0.8690\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 264s 11ms/step - loss: 0.1960 - acc: 0.9232 - val_loss: 0.3129 - val_acc: 0.8681\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.1630 - acc: 0.9383 - val_loss: 0.3674 - val_acc: 0.8678\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 263s 11ms/step - loss: 0.1345 - acc: 0.9504 - val_loss: 0.3742 - val_acc: 0.8698\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 272s 11ms/step - loss: 0.1047 - acc: 0.9614 - val_loss: 0.3985 - val_acc: 0.8643\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 268s 11ms/step - loss: 0.0825 - acc: 0.9704 - val_loss: 0.4386 - val_acc: 0.8648\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.98546731]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GRU, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(seq_embedded)\n",
    "        seq_conv = Conv1D(N, size, activation='tanh')(seq_hidden)\n",
    "        recursive_repr = GRU(N)(seq_conv)\n",
    "        sentiment = Dense(1)(recursive_repr)\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=10, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 246s 10ms/step - loss: 0.6688 - acc: 0.5499 - val_loss: 0.4159 - val_acc: 0.8123\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 242s 10ms/step - loss: 0.3659 - acc: 0.8383 - val_loss: 0.3170 - val_acc: 0.8612\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 241s 10ms/step - loss: 0.3120 - acc: 0.8676 - val_loss: 0.3006 - val_acc: 0.8698\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 237s 9ms/step - loss: 0.2874 - acc: 0.8776 - val_loss: 0.3160 - val_acc: 0.8622\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 237s 9ms/step - loss: 0.2623 - acc: 0.8904 - val_loss: 0.2983 - val_acc: 0.8744\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 235s 9ms/step - loss: 0.2395 - acc: 0.9027 - val_loss: 0.2925 - val_acc: 0.8733\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.2166 - acc: 0.9136 - val_loss: 0.2955 - val_acc: 0.8774\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 235s 9ms/step - loss: 0.1902 - acc: 0.9250 - val_loss: 0.3108 - val_acc: 0.8751\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.1681 - acc: 0.9351 - val_loss: 0.3349 - val_acc: 0.8676\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 191s 8ms/step - loss: 0.1447 - acc: 0.9461 - val_loss: 0.3426 - val_acc: 0.8636\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.93981749]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GRU, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh')(Dropout(0.2)(seq_hidden))\n",
    "        recursive_repr = GRU(N)(Dropout(0.2)(seq_conv))\n",
    "        sentiment = Dense(1)(Dropout(0.2)(recursive_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 219s 9ms/step - loss: 0.6853 - acc: 0.5331 - val_loss: 0.6603 - val_acc: 0.5762\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 216s 9ms/step - loss: 0.6729 - acc: 0.5844 - val_loss: 0.6708 - val_acc: 0.5466\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 209s 8ms/step - loss: 0.4896 - acc: 0.7744 - val_loss: 0.4113 - val_acc: 0.8129\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 270s 11ms/step - loss: 0.3722 - acc: 0.8356 - val_loss: 0.3208 - val_acc: 0.8614\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 274s 11ms/step - loss: 0.3432 - acc: 0.8502 - val_loss: 0.3253 - val_acc: 0.8573\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 20297s 812ms/step - loss: 0.3308 - acc: 0.8560 - val_loss: 0.3098 - val_acc: 0.8674\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 236s 9ms/step - loss: 0.3181 - acc: 0.8625 - val_loss: 0.2995 - val_acc: 0.8692\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 234s 9ms/step - loss: 0.3065 - acc: 0.8680 - val_loss: 0.2915 - val_acc: 0.8746\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 205s 8ms/step - loss: 0.3000 - acc: 0.8735 - val_loss: 0.2976 - val_acc: 0.8723\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 206s 8ms/step - loss: 0.2939 - acc: 0.8735 - val_loss: 0.2907 - val_acc: 0.8745\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 20266s 811ms/step - loss: 0.2840 - acc: 0.8802 - val_loss: 0.2830 - val_acc: 0.8825\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.2817 - acc: 0.8803 - val_loss: 0.2749 - val_acc: 0.8832\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.2737 - acc: 0.8845 - val_loss: 0.2853 - val_acc: 0.8789\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.2722 - acc: 0.8847 - val_loss: 0.3029 - val_acc: 0.8692\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.2671 - acc: 0.8881 - val_loss: 0.2764 - val_acc: 0.8829\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.91673148]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GRU, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=True)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh')(Dropout(0.2)(seq_hidden))\n",
    "        recursive_repr = GRU(N)(Dropout(0.2)(seq_conv))\n",
    "        sentiment = Dense(1)(Dropout(0.2)(recursive_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 236s 9ms/step - loss: 0.6853 - acc: 0.5355 - val_loss: 0.6445 - val_acc: 0.5778\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 224s 9ms/step - loss: 0.5460 - acc: 0.6940 - val_loss: 0.3461 - val_acc: 0.8540\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 222s 9ms/step - loss: 0.3095 - acc: 0.8704 - val_loss: 0.2930 - val_acc: 0.8801\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 432s 17ms/step - loss: 0.2517 - acc: 0.8979 - val_loss: 0.2939 - val_acc: 0.8775\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 261s 10ms/step - loss: 0.2213 - acc: 0.9123 - val_loss: 0.2935 - val_acc: 0.8807\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 241s 10ms/step - loss: 0.1913 - acc: 0.9268 - val_loss: 0.3349 - val_acc: 0.8721\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 233s 9ms/step - loss: 0.1745 - acc: 0.9340 - val_loss: 0.3514 - val_acc: 0.8694\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 235s 9ms/step - loss: 0.1560 - acc: 0.9419 - val_loss: 0.3410 - val_acc: 0.8748\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 255s 10ms/step - loss: 0.1401 - acc: 0.9486 - val_loss: 0.3578 - val_acc: 0.8761\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 265s 11ms/step - loss: 0.1259 - acc: 0.9527 - val_loss: 0.3687 - val_acc: 0.8666\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 255s 10ms/step - loss: 0.1164 - acc: 0.9566 - val_loss: 0.3831 - val_acc: 0.8713\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 231s 9ms/step - loss: 0.1071 - acc: 0.9622 - val_loss: 0.3675 - val_acc: 0.8715\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 239s 10ms/step - loss: 0.0984 - acc: 0.9650 - val_loss: 0.4115 - val_acc: 0.8697\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 223s 9ms/step - loss: 0.0892 - acc: 0.9690 - val_loss: 0.4297 - val_acc: 0.8677\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 242s 10ms/step - loss: 0.0880 - acc: 0.9681 - val_loss: 0.4259 - val_acc: 0.8680\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.99751067]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GRU, Input\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=True,\n",
    "                                 embeddings_regularizer=regularizers.l1(1e-4))(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh')(Dropout(0.2)(seq_hidden))\n",
    "        recursive_repr = GRU(N)(Dropout(0.2)(seq_conv))\n",
    "        sentiment = Dense(1)(Dropout(0.2)(recursive_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 261s 10ms/step - loss: 12.7019 - acc: 0.5245 - val_loss: 1.9663 - val_acc: 0.5365\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 242s 10ms/step - loss: 1.1994 - acc: 0.5304 - val_loss: 0.8885 - val_acc: 0.5428\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 289s 12ms/step - loss: 0.7997 - acc: 0.6358 - val_loss: 0.6382 - val_acc: 0.7862\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 282s 11ms/step - loss: 0.6308 - acc: 0.8184 - val_loss: 0.5781 - val_acc: 0.8556\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.5790 - acc: 0.8591 - val_loss: 0.5475 - val_acc: 0.8734\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 498s 20ms/step - loss: 0.5368 - acc: 0.8722 - val_loss: 0.5393 - val_acc: 0.8714\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 236s 9ms/step - loss: 0.5201 - acc: 0.8834 - val_loss: 0.5319 - val_acc: 0.8766\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 252s 10ms/step - loss: 0.5085 - acc: 0.8918 - val_loss: 0.5324 - val_acc: 0.8797\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 268s 11ms/step - loss: 0.4981 - acc: 0.8950 - val_loss: 0.5341 - val_acc: 0.8760\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 268s 11ms/step - loss: 0.4877 - acc: 0.8989 - val_loss: 0.5174 - val_acc: 0.8768\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 269s 11ms/step - loss: 0.4740 - acc: 0.9043 - val_loss: 0.5212 - val_acc: 0.8789\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 250s 10ms/step - loss: 0.4715 - acc: 0.9078 - val_loss: 0.5272 - val_acc: 0.8728\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 252s 10ms/step - loss: 0.4640 - acc: 0.9124 - val_loss: 0.5289 - val_acc: 0.8824\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 255s 10ms/step - loss: 0.4663 - acc: 0.9099 - val_loss: 0.5105 - val_acc: 0.8810\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 250s 10ms/step - loss: 0.4530 - acc: 0.9129 - val_loss: 0.5198 - val_acc: 0.8802\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.57911283]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GRU, Input\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=True)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh', kernel_regularizer=regularizers.l2(1e-4))(Dropout(0.5)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh', kernel_regularizer=regularizers.l2(1e-4))(Dropout(0.5)(seq_hidden))\n",
    "        recursive_repr = GRU(N)(Dropout(0.5)(seq_conv))\n",
    "        sentiment = Dense(1)(Dropout(0.5)(recursive_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 283s 11ms/step - loss: 0.7116 - acc: 0.5146 - val_loss: 0.6950 - val_acc: 0.5431\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 252s 10ms/step - loss: 0.6941 - acc: 0.5506 - val_loss: 0.6810 - val_acc: 0.5692\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 241s 10ms/step - loss: 0.4502 - acc: 0.8001 - val_loss: 0.3250 - val_acc: 0.8708\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 265s 11ms/step - loss: 0.3299 - acc: 0.8701 - val_loss: 0.3002 - val_acc: 0.8806\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 280s 11ms/step - loss: 0.3039 - acc: 0.8846 - val_loss: 0.3259 - val_acc: 0.8690\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 255s 10ms/step - loss: 0.2832 - acc: 0.8934 - val_loss: 0.3089 - val_acc: 0.8752\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 245s 10ms/step - loss: 0.2677 - acc: 0.9016 - val_loss: 0.3112 - val_acc: 0.8753\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 248s 10ms/step - loss: 0.2629 - acc: 0.9060 - val_loss: 0.2989 - val_acc: 0.8826\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 257s 10ms/step - loss: 0.2486 - acc: 0.9112 - val_loss: 0.3097 - val_acc: 0.8814\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 243s 10ms/step - loss: 0.2484 - acc: 0.9097 - val_loss: 0.3143 - val_acc: 0.8771\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 250s 10ms/step - loss: 0.2376 - acc: 0.9154 - val_loss: 0.3107 - val_acc: 0.8804\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.2274 - acc: 0.9191 - val_loss: 0.3193 - val_acc: 0.8786\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 265s 11ms/step - loss: 0.2235 - acc: 0.9206 - val_loss: 0.3201 - val_acc: 0.8767\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 257s 10ms/step - loss: 0.2131 - acc: 0.9252 - val_loss: 0.3260 - val_acc: 0.8752\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 272s 11ms/step - loss: 0.2120 - acc: 0.9274 - val_loss: 0.3339 - val_acc: 0.8760\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.49985394]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, GRU, Input, concatenate, add\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh', padding='same')(Dropout(0.2)(seq_hidden))\n",
    "        recursive_repr = GRU(N)(Dropout(0.2)(seq_hidden))  # !!!!!!!!!!!!!!\n",
    "        full_repr = concatenate([GlobalAveragePooling1D()(seq_hidden), GlobalMaxPooling1D()(seq_conv), recursive_repr])\n",
    "        sentiment = Dense(1)(Dropout(0.2)(full_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.4742 - acc: 0.7680 - val_loss: 0.3789 - val_acc: 0.8301\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 244s 10ms/step - loss: 0.3781 - acc: 0.8327 - val_loss: 0.3371 - val_acc: 0.8519\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 254s 10ms/step - loss: 0.3522 - acc: 0.8445 - val_loss: 0.3193 - val_acc: 0.8616\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 282s 11ms/step - loss: 0.3330 - acc: 0.8564 - val_loss: 0.3063 - val_acc: 0.8670\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 285s 11ms/step - loss: 0.3163 - acc: 0.8644 - val_loss: 0.2938 - val_acc: 0.8743\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.3068 - acc: 0.8694 - val_loss: 0.2848 - val_acc: 0.8795\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 247s 10ms/step - loss: 0.2923 - acc: 0.8753 - val_loss: 0.2767 - val_acc: 0.8829\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 268s 11ms/step - loss: 0.2815 - acc: 0.8807 - val_loss: 0.2960 - val_acc: 0.8747\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 250s 10ms/step - loss: 0.2745 - acc: 0.8864 - val_loss: 0.2744 - val_acc: 0.8838\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 265s 11ms/step - loss: 0.2656 - acc: 0.8874 - val_loss: 0.2731 - val_acc: 0.8859\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 264s 11ms/step - loss: 0.2587 - acc: 0.8924 - val_loss: 0.2911 - val_acc: 0.8796\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 267s 11ms/step - loss: 0.2525 - acc: 0.8945 - val_loss: 0.2683 - val_acc: 0.8878\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 257s 10ms/step - loss: 0.2470 - acc: 0.8977 - val_loss: 0.2733 - val_acc: 0.8863\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 260s 10ms/step - loss: 0.2393 - acc: 0.9023 - val_loss: 0.2850 - val_acc: 0.8788\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 243s 10ms/step - loss: 0.2323 - acc: 0.9057 - val_loss: 0.2647 - val_acc: 0.8886\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.9398315]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, GRU, Input, concatenate, add\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh', padding='same')(Dropout(0.2)(seq_hidden))\n",
    "        recursive_repr = GRU(N)(Dropout(0.2)(seq_hidden))  # !!!!!!!!!!!!!!\n",
    "        full_repr = add([GlobalAveragePooling1D()(seq_hidden), GlobalMaxPooling1D()(seq_conv), recursive_repr])\n",
    "        sentiment = Dense(1)(Dropout(0.2)(full_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 245s 10ms/step - loss: 0.4829 - acc: 0.7582 - val_loss: 0.3713 - val_acc: 0.8356\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 222s 9ms/step - loss: 0.3767 - acc: 0.8349 - val_loss: 0.3305 - val_acc: 0.8570\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 3878s 155ms/step - loss: 0.3403 - acc: 0.8516 - val_loss: 0.3100 - val_acc: 0.8674\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 241s 10ms/step - loss: 0.3201 - acc: 0.8606 - val_loss: 0.2905 - val_acc: 0.8754\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 240s 10ms/step - loss: 0.3039 - acc: 0.8713 - val_loss: 0.2838 - val_acc: 0.8774\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 238s 10ms/step - loss: 0.2916 - acc: 0.8758 - val_loss: 0.2759 - val_acc: 0.8840\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 236s 9ms/step - loss: 0.2828 - acc: 0.8804 - val_loss: 0.2743 - val_acc: 0.8848\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 257s 10ms/step - loss: 0.2757 - acc: 0.8824 - val_loss: 0.3210 - val_acc: 0.8692\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 251s 10ms/step - loss: 0.2702 - acc: 0.8858 - val_loss: 0.2926 - val_acc: 0.8780\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 240s 10ms/step - loss: 0.2626 - acc: 0.8906 - val_loss: 0.2747 - val_acc: 0.8840\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 240s 10ms/step - loss: 0.2513 - acc: 0.8945 - val_loss: 0.2696 - val_acc: 0.8884\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 242s 10ms/step - loss: 0.2486 - acc: 0.8967 - val_loss: 0.2819 - val_acc: 0.8858\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 270s 11ms/step - loss: 0.2429 - acc: 0.8965 - val_loss: 0.2645 - val_acc: 0.8880\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 245s 10ms/step - loss: 0.2351 - acc: 0.9030 - val_loss: 0.2654 - val_acc: 0.8884\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 243s 10ms/step - loss: 0.2341 - acc: 0.9039 - val_loss: 0.2753 - val_acc: 0.8881\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.98081231]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, GRU, Input, concatenate, add\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=64, size=3):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh', padding='same')(Dropout(0.2)(seq_hidden))\n",
    "        seq_hidden = add([seq_hidden, seq_conv])\n",
    "        recursive_repr = GRU(N)(Dropout(0.2)(seq_hidden))\n",
    "        sentiment = Dense(1)(Dropout(0.2)(recursive_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 245s 10ms/step - loss: 0.6553 - acc: 0.5832 - val_loss: 0.5073 - val_acc: 0.7815\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 252s 10ms/step - loss: 0.4638 - acc: 0.7801 - val_loss: 0.3531 - val_acc: 0.8464\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 241s 10ms/step - loss: 0.3566 - acc: 0.8450 - val_loss: 0.3126 - val_acc: 0.8631\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 232s 9ms/step - loss: 0.3350 - acc: 0.8538 - val_loss: 0.3016 - val_acc: 0.8717\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 284s 11ms/step - loss: 0.3138 - acc: 0.8653 - val_loss: 0.3160 - val_acc: 0.8576\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 580s 23ms/step - loss: 0.3074 - acc: 0.8688 - val_loss: 0.2865 - val_acc: 0.8770\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 233s 9ms/step - loss: 0.2920 - acc: 0.8774 - val_loss: 0.2749 - val_acc: 0.8832\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 211s 8ms/step - loss: 0.2819 - acc: 0.8806 - val_loss: 0.2719 - val_acc: 0.8860\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.2753 - acc: 0.8845 - val_loss: 0.2718 - val_acc: 0.8838\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 212s 8ms/step - loss: 0.2665 - acc: 0.8896 - val_loss: 0.2710 - val_acc: 0.8852\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.2607 - acc: 0.8915 - val_loss: 0.3029 - val_acc: 0.8710\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 218s 9ms/step - loss: 0.2575 - acc: 0.8921 - val_loss: 0.2663 - val_acc: 0.8866\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 220s 9ms/step - loss: 0.2516 - acc: 0.8950 - val_loss: 0.2669 - val_acc: 0.8870\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 204s 8ms/step - loss: 0.2497 - acc: 0.8957 - val_loss: 0.2687 - val_acc: 0.8879\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.2403 - acc: 0.9022 - val_loss: 0.3001 - val_acc: 0.8800\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.90629309]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, GRU, Input, concatenate, add\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class GloveCNNGRUSentimentModel(object):\n",
    "    def __init__(self, seq_len=seq_cutoff, N=96, size=5):\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.model = self.create(N, size)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def create(self, N, size):\n",
    "        seq_indices = Input(shape=(self.seq_len,), name='seq_input')                    \n",
    "        seq_embedded = Embedding(input_dim=len(vocab) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                                 input_length=self.seq_len, trainable=False)(seq_indices)\n",
    "        seq_hidden = Dense(N, activation='tanh')(Dropout(0.2)(seq_embedded))\n",
    "        seq_conv = Conv1D(N, size, activation='tanh', padding='same')(Dropout(0.2)(seq_hidden))\n",
    "        seq_hidden = add([seq_hidden, seq_conv])\n",
    "        recursive_repr = GRU(N)(Dropout(0.2)(seq_hidden))\n",
    "        sentiment = Dense(1)(Dropout(0.2)(recursive_repr))\n",
    "        # normalize to [0, 1] range\n",
    "        sentiment = Activation('sigmoid')(sentiment)\n",
    "\n",
    "        return Model(input=seq_indices, output=sentiment)\n",
    "        \n",
    "    def review_vector(self, tokens):\n",
    "        vector = [0] * self.seq_len\n",
    "        if len(tokens) > self.seq_len:\n",
    "            # Remove the middle\n",
    "            tokens = tokens[: self.seq_len // 2] + ['SINGLE_PADDING_IN_THE_MIDDLE'] + tokens[-self.seq_len // 2 :]\n",
    "        for i, t in enumerate(tokens):\n",
    "            try:\n",
    "                vector[i] = vocab.index(t) + 1  # reserving 0 for padding\n",
    "            except:\n",
    "                pass  # ignore missing words\n",
    "        return vector\n",
    "\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        print('Vectorizing...')\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        X_val = np.array([self.review_vector(r) for r in X_val], dtype='int32')\n",
    "        print('Fitting...')\n",
    "        self.model.fit(X, y, validation_data=(X_val, y_val), epochs=15, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array([self.review_vector(r) for r in X], dtype='int32')\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Fitting...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 352s 14ms/step - loss: 0.6499 - acc: 0.5782 - val_loss: 0.4484 - val_acc: 0.7847\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 339s 14ms/step - loss: 0.3800 - acc: 0.8325 - val_loss: 0.3208 - val_acc: 0.8596\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 1646s 66ms/step - loss: 0.3367 - acc: 0.8536 - val_loss: 0.3194 - val_acc: 0.8624\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 328s 13ms/step - loss: 0.3158 - acc: 0.8659 - val_loss: 0.3333 - val_acc: 0.8537\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 334s 13ms/step - loss: 0.2987 - acc: 0.8722 - val_loss: 0.2906 - val_acc: 0.8778\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 340s 14ms/step - loss: 0.2913 - acc: 0.8784 - val_loss: 0.2852 - val_acc: 0.8784\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 357s 14ms/step - loss: 0.2737 - acc: 0.8856 - val_loss: 0.2857 - val_acc: 0.8830\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 443s 18ms/step - loss: 0.2665 - acc: 0.8876 - val_loss: 0.2795 - val_acc: 0.8832\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 5947s 238ms/step - loss: 0.2566 - acc: 0.8933 - val_loss: 0.2782 - val_acc: 0.8843\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 368s 15ms/step - loss: 0.2464 - acc: 0.8976 - val_loss: 0.2764 - val_acc: 0.8830\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 369s 15ms/step - loss: 0.2403 - acc: 0.8995 - val_loss: 0.2759 - val_acc: 0.8858\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 388s 16ms/step - loss: 0.2361 - acc: 0.9012 - val_loss: 0.2797 - val_acc: 0.8841\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 399s 16ms/step - loss: 0.2236 - acc: 0.9096 - val_loss: 0.3016 - val_acc: 0.8794\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 388s 16ms/step - loss: 0.2176 - acc: 0.9103 - val_loss: 0.2838 - val_acc: 0.8847\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 356s 14ms/step - loss: 0.2160 - acc: 0.9124 - val_loss: 0.2827 - val_acc: 0.8832\n",
      "Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story. [ 0.89099598]\n"
     ]
    }
   ],
   "source": [
    "sentiment = GloveCNNGRUSentimentModel()\n",
    "sentiment.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_text = 'Good story about a backwoods community in the Ozarks around the turn of the century. Moonshine is the leading industry, fighting and funning the major form of entertainment. One day a stranger enters the community and causes a shake-up among the locals. Beautiful scenery adds much to the story.'\n",
    "test_tokens = text_tokens(test_text)\n",
    "print(test_text, sentiment.predict([test_tokens])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
